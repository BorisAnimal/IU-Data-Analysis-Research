{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x,y=None):\n",
    "    if y==None:\n",
    "        tmp = range(len(x))\n",
    "        y = x\n",
    "        x = tmp\n",
    "    fig, ax = plt.subplots(figsize=(16,2))\n",
    "    ax.plot(x,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'dataset/REFIT_BUILDING_SURVEY.xml'\n",
    "tree = objectify.parse(path)\n",
    "root = tree.getroot()\n",
    "NS={'a':'http://www.refitsmarthomes.org'}\n",
    "\n",
    "path=r'dataset/REFIT_TIME_SERIES_VALUES.csv'\n",
    "\n",
    "try:\n",
    "    csv\n",
    "except:\n",
    "    csv=pd.read_csv(path, index_col=0, parse_dates=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy consumption in home\n",
    "def get_energy():\n",
    "    \"\"\"\n",
    "        Available only for 1st building, due to needs a lot of memory on drive\n",
    "    \"\"\"\n",
    "    \n",
    "    path = r'dataset/CLEAN_House1.csv'\n",
    "    csvnrg=pd.read_csv(path, header=0,usecols=[\"Time\", \"Aggregate\"], parse_dates=[0])\n",
    "\n",
    "    data_en = csvnrg['Aggregate'].tolist()\n",
    "    time_en = csvnrg['Time'].tolist()\n",
    "\n",
    "#     plot(time_en, data_en)\n",
    "    \n",
    "    return data_en, time_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values of (gas based) Radiator temperature sensor\n",
    "def get_radiator(building_num=1, rad_num=2):\n",
    "    appliance = 'Radiator[%d]' % (rad_num)\n",
    "    NS={'a':'http://www.refitsmarthomes.org'}\n",
    "    \n",
    "    radiators = root.xpath('./a:Stock/a:Building[%d]/a:%s' % (building_num, appliance), namespaces=NS)\n",
    "\n",
    "    data_rad = []\n",
    "    time_rad = []\n",
    "\n",
    "    for rad in radiators:\n",
    "        r_id = rad.get('id')\n",
    "        t = []\n",
    "        v = []\n",
    "        for sensor in rad.getchildren():\n",
    "            for time_series_variable in sensor.getchildren():\n",
    "                id = time_series_variable.get('id')\n",
    "                t.append(csv.loc[id]['dateTime'].tolist())\n",
    "                v.append(csv.loc[id]['data'].values.tolist())\n",
    "        data_rad = list(itertools.chain.from_iterable(v))\n",
    "        time_rad = list(itertools.chain.from_iterable(t))\n",
    "    \n",
    "    return data_rad, time_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summs values for intervals\n",
    "\n",
    "by_day = lambda t: t.day\n",
    "by_week = lambda t: t.week\n",
    "by_month = lambda t: t.month\n",
    "    \n",
    "act_sum = lambda s, vi: s + vi\n",
    "act_max = lambda s, vi: max(s,vi)\n",
    "act_min = lambda s, vi: min(s,vi)\n",
    "    \n",
    "def act_interval(check_param, action, times, values):\n",
    "    t = []\n",
    "    v = []\n",
    "    s = values[0]\n",
    "    for i in range(1, len(times)):\n",
    "        if check_param(times[i]) == check_param(times[i-1]):\n",
    "            s = action(s, values[i])\n",
    "        else:\n",
    "            v.append(s)\n",
    "            t.append(times[i])\n",
    "            s = values[i]\n",
    "    return t,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage of gas in home\n",
    "\n",
    "def get_gas(building_num=1):\n",
    "    appliance = 1 #Number of gas meter\n",
    "    NS={'a':'http://www.refitsmarthomes.org'}\n",
    "    tsv = root.xpath('./a:Stock/a:Building[%d]/a:Meter[%d]/a:Sensor/a:TimeSeriesVariable' % (building_num, appliance), namespaces=NS)\n",
    "\n",
    "    id = tsv[0].get('id')\n",
    "\n",
    "    time_gas = csv.loc[id]['dateTime'].tolist()\n",
    "    data_gas = csv.loc[id]['data'].values.tolist()\n",
    "    \n",
    "    time_gas, data_gas = act_interval(by_day, act_sum, time_gas, data_gas)\n",
    "    \n",
    "    return data_gas, time_gas\n",
    "\n",
    "\n",
    "def get_fft(data):\n",
    "    from numpy.fft import rfft\n",
    "    fg = rfft(data).real\n",
    "#     print('gas day sum FFT coefficients')\n",
    "#     plot(fg)\n",
    "#     len(fg)\n",
    "    \n",
    "    return fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Weather data \n",
    "def get_clim():\n",
    "    NS={'a':'http://www.refitsmarthomes.org'}\n",
    "    elements=root.xpath('./a:Stock/a:Climate/a:Sensor/a:TimeSeriesVariable', namespaces=NS)\n",
    "    data_clim = []\n",
    "    time_clim = []\n",
    "    for e in elements:\n",
    "        id = e.get('id')\n",
    "        variable_type=e.get('variableType')\n",
    "        units=e.get('units')\n",
    "        t,v = act_interval(by_day, act_min, csv.loc[id]['dateTime'].tolist(), csv.loc[id]['data'].tolist())\n",
    "        data_clim.append(v)\n",
    "        if len(time_clim) == 0:\n",
    "            time_clim = t\n",
    "        else: \n",
    "            assert len(time_clim) == len(t)\n",
    "    \n",
    "    return data_clim, time_clim\n",
    "#         ax.plot(csv.loc[id]['dateTime'],csv.loc[id]['data'])\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = elements[0]\n",
    "# climate_sensors = []\n",
    "# for i in elements:\n",
    "#     climate_sensors.append(i.attrib['variableType'])\n",
    "# print(climate_sensors)\n",
    "# #indexes: 0, 1, 2, -2, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: try LSTM model to predict gas consumption \n",
    "\n",
    "#Changeable parameters:\n",
    "# building_num = 2      #Begins from 1 (not 0) ):\n",
    "# gap = 7               #len (days before now) for FFT (for input layer of LSTM)\n",
    "\n",
    "def prepare_data(building_num=2, gap=7):\n",
    "    data_gas, time_gas = get_gas(building_num)\n",
    "    data_clim, time_clim = get_clim()\n",
    "\n",
    "#     print('Initial data:')\n",
    "#     print('len(gas): ', len(time_gas))\n",
    "#     print('len(clim): ', len(time_clim))\n",
    "\n",
    "    #align dates in intervals\n",
    "    #meter must be @gap days before now\n",
    "    #climate must begin day after now (tommorow)\n",
    "\n",
    "#     print('First possible date of gas (with gap shifting): ', time_gas[gap])\n",
    "#     print('First date of clim: ', time_clim[0])\n",
    "    begin = time_gas.index(time_clim[0]) - gap\n",
    "    time_gas = time_gas[begin:]\n",
    "    data_gas = data_gas[begin:]\n",
    "\n",
    "    end = time_clim.index(time_gas[-1]) + 1\n",
    "    time_clim = time_clim[:end]\n",
    "\n",
    "#     print('After formatting: ')\n",
    "#     print(len(time_gas))\n",
    "#     print(len(time_clim))\n",
    "#     print('first')\n",
    "#     print(time_gas[gap])\n",
    "#     print(time_clim[0])\n",
    "\n",
    "#     print('last')\n",
    "#     print(time_gas[-1])\n",
    "#     print(time_clim[-1])\n",
    "\n",
    "    tmp = []\n",
    "    for d in data_clim:\n",
    "        tmp.append(d[:end])\n",
    "    data_clim = tmp\n",
    "    \n",
    "    #Prepare data to train LSTM\n",
    "\n",
    "    xinp = [] #Construct of 0-3: FFT coefficients, 4-weather forecast values on tommorow\n",
    "    ypred = []\n",
    "    \n",
    "    from numpy.fft import rfft\n",
    "    for idx in range(gap, len(time_gas)-1):\n",
    "        item = time_gas[idx]\n",
    "        row = rfft(data_gas[idx-gap:idx]).real.tolist()\n",
    "        ypred.append(data_gas[idx+1])\n",
    "        #add weather forecast\n",
    "        widx = time_clim.index(item) #weather's series index for current date\n",
    "        row.append(data_clim[0][widx+1])\n",
    "        row.append(data_clim[1][widx+1])\n",
    "        row.append(data_clim[2][widx+1])\n",
    "        row.append(data_clim[-2][widx+1])\n",
    "        row.append(data_clim[-1][widx+1])\n",
    "\n",
    "        xinp.append(row)\n",
    "\n",
    "#     print(xinp[-1])\n",
    "#     print(ypred[-1])\n",
    "    \n",
    "    return xinp, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store input and output\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "def get_data(building_num=2, gap=7):\n",
    "    finp = 'inp_building=%d_gap=%d.pkl' % (building_num, gap)\n",
    "    fout = 'out_building=%d_gap=%d.pkl' % (building_num, gap)\n",
    "\n",
    "    if os.path.exists(finp) and os.path.exists(fout):\n",
    "        with open('inp.pkl', 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        with open('pred.pkl', 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "    else:\n",
    "        X,Y = prepare_data(building_num, gap)\n",
    "        \n",
    "        #Store\n",
    "        with open(finp, 'wb') as f:\n",
    "            pickle.dump(X, f)\n",
    "        with open(fout, 'wb') as f:\n",
    "            pickle.dump(Y, f)\n",
    "            \n",
    "    return numpy.array(X).astype('float32'), numpy.array(Y).astype('float32').reshape(-1,1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def saveAsText(xinp, ypred):\n",
    "    with open('inp.txt', 'w') as f:\n",
    "        for i in xinp:\n",
    "            f.write(', '.join(map(str, i)))\n",
    "            f.write('\\n')\n",
    "    with open('out.txt', 'w') as f:\n",
    "        for i in ypred:\n",
    "            f.write(str(i))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN (LSTM) building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train LSTM\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras import backend as K\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frameX = pandas.read_csv('inp.txt', engine='python')\n",
    "# setX = frameX.values\n",
    "# setX = setX.astype('float32')\n",
    "\n",
    "building   = 2\n",
    "gap        = 5\n",
    "split      = 0.67\n",
    "neurons    = 100\n",
    "epochs     = 30\n",
    "batch_size = 10\n",
    "\n",
    "setX, setY = get_data(building, gap)\n",
    "\n",
    "# normalize the setX\n",
    "scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "setX = scalerX.fit_transform(setX)\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(setX) * split)\n",
    "test_size = len(setX) - train_size\n",
    "train, test = setX[0:train_size,:], setX[train_size:len(setX),:]\n",
    "\n",
    "# convert an array of values into a setX matrix\n",
    "trainX = numpy.reshape(train, (train.shape[0], 1, train.shape[1]))\n",
    "testX = numpy.reshape(test, (test.shape[0], 1, test.shape[1]))\n",
    "\n",
    "#Scale\n",
    "\n",
    "scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "setY = scalerY.fit_transform(setY)\n",
    "trainY, testY = setY[0:train_size,:], setY[train_size:len(setY),:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#design and fit our LSTM network\n",
    "   \n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(neurons))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_data=(testX, testY), verbose=0, shuffle=False)\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scalerY.inverse_transform(trainPredict)\n",
    "trainInvY = scalerY.inverse_transform(trainY)\n",
    "testPredict = scalerY.inverse_transform(testPredict)\n",
    "testInvY = scalerY.inverse_transform(testY)\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainInvY, trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testInvY, testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfull param combinations: \n",
    " * gap        = 5\n",
    " * split      = 0.67\n",
    " * neurons    = 100\n",
    " * epochs     = 40\n",
    " * batch_size = 10\n",
    " * Train Score: 0.94 RMSE\n",
    " * Test Score: 1.10 RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "trainPredict = scalerY.inverse_transform(trainPredict)\n",
    "trainInvY = scalerY.inverse_transform(trainY)\n",
    "testPredict = scalerY.inverse_transform(testPredict)\n",
    "testInvY = scalerY.inverse_transform(testY)\n",
    "# calculate root mean squared error\n",
    "tmp = mean_squared_error(trainInvY, trainPredict[:,0])\n",
    "trainScore = math.sqrt(tmp)\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testInvY, testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(setY)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[:len(trainPredict), :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(setY)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict):len(setY), :] = testPredict\n",
    "# plot baseline and predictions\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "ax.plot(scalerY.inverse_transform(setY))\n",
    "ax.plot(trainPredictPlot)\n",
    "ax.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(map(int, scalerY.inverse_transform(setY[len(trainPredict):])))\n",
    "b = list(map(int, testPredict))\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "ax.plot(a)\n",
    "ax.plot(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to release gpu\n",
    "\n",
    "def free_gpu():\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        print('No model')\n",
    "    try:\n",
    "        del history\n",
    "    except:\n",
    "        print('No history')\n",
    "    import gc\n",
    "    K.clear_session()\n",
    "    for i in range(15): gc.collect()\n",
    "\n",
    "free_gpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
